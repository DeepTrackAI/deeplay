{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing Templates and Components\n",
    "\n",
    "**Why Customize?**\n",
    "\n",
    "While Deeplay provides a robust set of pre-defined templates and components, there may be cases where you'd like to customize these to better suit your specific problem. Customization can range from minor changes to existing templates to creating entirely new components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization using Config\n",
    "\n",
    "**Decoding Automatic Summaries**\n",
    "\n",
    "When you print your model using `print(model)`, `deeplay` will provide an automatic summary that shows the hierarchical structure of the model. Your `Config` object should mirror this hierarchy, allowing you to easily set or modify specific attributes and layers within the model. For example, let's look at the initial lines of the `ImageClassifier` summary:\n",
    "\n",
    "```python\n",
    "ImageClassifier(\n",
    "  (backbone): ConvolutionalEncoder(\n",
    "    (blocks): ModuleList(\n",
    "      (0): Template(\n",
    "        (layer): LazyConv2d(0, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        (activation): ReLU()\n",
    "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "      )\n",
    "    ... continues\n",
    "```\n",
    "\n",
    "Pay attention to the names within parentheses â€” `backbone`, `blocks`, `0`, and `layer`. To change the `kernel_size` attribute, you can create a `Config` object that mimics this structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import Config \n",
    "\n",
    "config = Config().backbone.blocks[0].layer.kernel_size(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you want to update many blocks at once, you can use slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config().backbone.blocks[0:4].layer.kernel_size(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you want to update all blocks at once, you can omit the indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config().backbone.blocks.layer.kernel_size(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Just like you can update attributes of the layers, you can also change the type of layers themselves. For instance, to change the activation function to `LeakyReLU` for all blocks, you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bmidt\\DeepTorch\\notebooks\\getting-started\\Ch04-Customization.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bmidt/DeepTorch/notebooks/getting-started/Ch04-Customization.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m config \u001b[39m=\u001b[39m Config()\u001b[39m.\u001b[39mbackbone\u001b[39m.\u001b[39mblocks\u001b[39m.\u001b[39mactivation(nn\u001b[39m.\u001b[39mLeakyReLU, negative_slope\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "config = Config().backbone.blocks.activation(nn.LeakyReLU, negative_slope=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you to easily swap out modules and tune the model to better fit your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Customization using Templates\n",
    "\n",
    "**Switching to a More Complex Block Design**\n",
    "\n",
    "Let's continue from our previous example. Deeplay allows you to define the structure of your blocks via templates. A template specifies the sequence and type of layers you want to stack together in a block. Here's how you can define a new template to include a batch normalization layer in each block:\n",
    "\n",
    "This level of customization opens up a wide array of possibilities, allowing you to quickly experiment with various architectures while keeping the rest of your setup intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import Layer\n",
    "\n",
    "block_template = Layer(\"layer\") >> Layer(\"activation\") >> Layer(\"normalization\") >> Layer(\"pool\")\n",
    "\n",
    "config = (\n",
    "    Config()\n",
    "    .backbone.blocks(block_template)\n",
    "    .backbone.blocks.normalization(nn.LazyBatchNorm2d)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The string you pass into the `Layer` object directly corresponds to the name you'll use in the `Config` object. This is how Deeplay knows what layer you're trying to customize or add. For example, the `\"normalization\"` string in `Layer(\"normalization\")` is what you'll use to set the normalization layer type in the config, as in `.backbone.blocks.normalization(nn.LazyBatchNorm2d)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It's worth noting that `normalization` wasn't a default component in the original `ImageClassifier`. By adding* it to our custom `block_template`, we've effectively expanded the architecture of the model. After adding a new layer to a template, you should also specify its settings in the Config. Here, we're setting it to use `nn.LazyBatchNorm2d`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Pretrained Torch Modules\n",
    "\n",
    "**Incorporate Pretrained Models for a Quick Start**\n",
    "\n",
    "Deeplay allows for seamless integration of pretrained PyTorch models, making it incredibly easy to leverage existing architectures. Take for example a pretrained ResNet-18 model from torchvision:\n",
    "\n",
    "This offers a quick and straightforward way to benefit from well-established architectures while still maintaining the flexibility that Deeplay provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifier(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): Identity()\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (connector): Flatten(start_dim=1, end_dim=-1)\n",
      "  (head): CategoricalClassificationHead(\n",
      "    (output): Template(\n",
      "      (layer): LazyLinear(in_features=0, out_features=10, bias=True)\n",
      "      (activation): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (val_accuracy): MulticlassAccuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from deeplay import ImageClassifier\n",
    "\n",
    "backbone = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Remove the pooling and fully connected layers as they are not needed\n",
    "backbone.avgpool = nn.Identity()\n",
    "backbone.fc = nn.Identity()\n",
    "\n",
    "classifier = ImageClassifier.from_config(\n",
    "    Config()\n",
    "    .num_classes(10)\n",
    "    .backbone(backbone)\n",
    ")\n",
    "\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here, we directly use the pretrained ResNet-18 model as the `backbone` in our `ImageClassifier`. Note that you might need to remove or adapt certain layers, like we did with the average pooling (`avgpool`) and fully connected (`fc`) layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Non-Deeplay modules cannot be further customized using Deeplay. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Customizing Loss and Optimizer\n",
    "\n",
    "**Setting Loss Function and its Parameters**\n",
    "\n",
    "To change the loss function used in the training process, you can specify it in your Config object. This customization is especially useful when your problem has specific requirements that aren't met by the default loss functions.\n",
    "\n",
    "For instance, let's say you want to use the Mean Squared Error (MSE) loss function and set its reduction method to \"sum\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import Config\n",
    "import torch.nn as nn\n",
    "\n",
    "config = Config().loss(nn.MSELoss, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Changing the loss function is generally only possible for Applications, as these are the objects that contain end-to-end training and validation logic.\n",
    "\n",
    "**Setting Optimizer and Learning Rate**\n",
    "\n",
    "Similarly, you can easily customize the optimizer. Deeplay supports any PyTorch compatible optimizer. To use the Adam optimizer with a learning rate of 0.001, you would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config().optimizer(torch.optim.Adam, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this flexibility, you can easily experiment with different combinations of loss functions and optimizers to find the optimal setting for your specific problem.\n",
    "\n",
    "That wraps up our section on customizing the loss and optimizer. Next, you'll see how to combine all these customizations to create a model that perfectly fits your needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
