{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Creating Your Own Application: `MyImageClassifier`\n",
    "\n",
    "Creating your own application involves defining a new class that inherits from Deeplay's `Application` class. You can then customize this class to better align with your specific needs. Here's how:\n",
    "\n",
    "#### Defining Defaults\n",
    "\n",
    "The `defaults` attribute sets up a `Config` object with default configurations for various components like the backbone, connector, head, loss, and optimizer. These defaults can be overridden when creating a new instance of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from deeplay import Application, Config, ConvolutionalEncoder, CategoricalClassificationHead\n",
    "\n",
    "\n",
    "class MyImageClassifier(Application):\n",
    "\n",
    "    defaults = (\n",
    "        Config()\n",
    "        .backbone(ConvolutionalEncoder)\n",
    "        .connector(nn.Flatten)\n",
    "        .head(CategoricalClassificationHead)\n",
    "        .loss(nn.CrossEntropyLoss)\n",
    "        .optimizer(torch.optim.Adam, lr=0.001)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: For convenience, the `defaults` attribute is a class attribute, so you can access it without instantiating the class. This is useful when you want to see what the default configurations are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model attributes\n",
    "\n",
    "Applications can also have attributes. These are useful for storing information about the model that you might want to access later. For example, you might want to store the number of classes in the dataset, or the size of the input images. You can define these attributes in the default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyImageClassifier(Application):\n",
    "\n",
    "    defaults = (\n",
    "        Config()\n",
    "        .num_classes(10)\n",
    "        .backbone(ConvolutionalEncoder)\n",
    "        .connector(nn.Flatten)\n",
    "        .head(CategoricalClassificationHead)\n",
    "        .loss(nn.CrossEntropyLoss)\n",
    "        .optimizer(torch.optim.Adam, lr=0.001)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it does not make sense to have a default value for the number of classes, so it will be omitted from the default configuration. Nonetheless, the `head` needs to know the number of classes in the dataset. We want to make sure this is the same as the `num_classes` attribute passed by the user. We can achieve this using the `Ref` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import Ref\n",
    "\n",
    "class MyImageClassifier(Application):\n",
    "\n",
    "    defaults = (\n",
    "        Config()\n",
    "        .backbone(ConvolutionalEncoder)\n",
    "        .connector(nn.Flatten)\n",
    "        .head(CategoricalClassificationHead, num_classes=Ref('num_classes'))\n",
    "        .loss(nn.CrossEntropyLoss)\n",
    "        .optimizer(torch.optim.Adam, lr=0.001)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We could also force the user to set `head.num_classes` directly, but doing it this way allows the very user-friendly syntax:\n",
    "\n",
    "```python\t\n",
    "MyImageClassifier(num_classes=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### The Constructor: `__init__`\n",
    "\n",
    "The constructor function (`__init__`) initializes the various components of the model. In this case, we define the `backbone`, `connector`, and `head` components. We use the `new` method to instantiate these components based on the class or configuration passed during the class initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyImageClassifier(Application):\n",
    "\n",
    "    defaults = (\n",
    "        Config()\n",
    "        .backbone(ConvolutionalEncoder)\n",
    "        .connector(nn.Flatten)\n",
    "        .head(CategoricalClassificationHead, num_classes=Ref('num_classes'))\n",
    "        .loss(nn.CrossEntropyLoss)\n",
    "        .optimizer(torch.optim.Adam, lr=0.001)\n",
    "    )\n",
    "\n",
    "    def __init__(self, backbone=None, connector=None, head=None, loss=None, optimizer=None):\n",
    "        super().__init__(backbone=backbone, connector=connector, head=head, loss=loss, optimizer=optimizer)\n",
    "        \n",
    "        # Attributes\n",
    "        self.num_classes = self.attr(\"num_classes\")\n",
    "\n",
    "        # Modules\n",
    "        self.backbone = self.new(\"backbone\")\n",
    "        self.connector = self.new(\"connector\")\n",
    "        self.head = self.new(\"head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We don't need to accept arguments in the constructor function. However, we consider it a good practice to accept arguments of the same name as the components. This helps making the class self-documenting and also allows us allows the alternate model instantiation syntax shown below.\n",
    "\n",
    "```python\n",
    "model = MyImageClassifier(backbone=ConvolutionalEncoder, head=CategoricalClassificationHead)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### The Forward Pass: `forward`\n",
    "\n",
    "Finally, the `forward` method defines how the input data flows through these components. It uses the instantiated objects of the backbone, connector, and head components to process the input and produce the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyImageClassifier(Application):\n",
    "\n",
    "    defaults = (\n",
    "        Config()\n",
    "        .backbone(ConvolutionalEncoder)\n",
    "        .connector(nn.Flatten)\n",
    "        .head(CategoricalClassificationHead, num_classes=Ref('num_classes'))\n",
    "        .loss(nn.CrossEntropyLoss)\n",
    "        .optimizer(torch.optim.Adam, lr=0.001)\n",
    "    )\n",
    "\n",
    "    def __init__(self, backbone=None, connector=None, head=None, loss=None, optimizer=None):\n",
    "        super().__init__(backbone=backbone, connector=connector, head=head, loss=loss, optimizer=optimizer)\n",
    "        \n",
    "        # Attributes\n",
    "        self.num_classes = self.attr(\"num_classes\")\n",
    "\n",
    "        # Modules\n",
    "        self.backbone = self.new(\"backbone\")\n",
    "        self.connector = self.new(\"connector\")\n",
    "        self.head = self.new(\"head\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.connector(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following these three main steps—defining defaults, initializing components, and specifying the forward pass—you can create a new, custom application class tailored for your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyImageClassifier(\n",
      "  (backbone): ConvolutionalEncoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Template(\n",
      "        (layer): LazyConv2d(0, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation): ReLU()\n",
      "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (1): Template(\n",
      "        (layer): LazyConv2d(0, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation): ReLU()\n",
      "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (2): Template(\n",
      "        (layer): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation): ReLU()\n",
      "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (3): Template(\n",
      "        (layer): LazyConv2d(0, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (activation): ReLU()\n",
      "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (connector): Flatten(start_dim=1, end_dim=-1)\n",
      "  (head): CategoricalClassificationHead(\n",
      "    (output): Template(\n",
      "      (layer): LazyLinear(in_features=0, out_features=None, bias=True)\n",
      "      (activation): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "classifier = MyImageClassifier()\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending Application Functionality: Leveraging LightningModule\n",
    "\n",
    "Deeplay's `Application` class is built upon PyTorch Lightning's `LightningModule`. This means you have the power to override methods like `training_step`, `validation_step`, etc., to add your own custom logic for these stages. This is especially useful for incorporating unique training behaviors or custom metrics.\n",
    "\n",
    "#### Adding Custom Training and Validation Steps\n",
    "\n",
    "Below is an example where we extend the `MyImageClassifier` class to include custom training and validation steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomImageClassifier(MyImageClassifier):\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Extract data and targets from batch\n",
    "        x, y = batch\n",
    "\n",
    "        # Forward pass\n",
    "        logits = self(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss(logits, y)\n",
    "\n",
    "        # Log training loss\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Extract data and targets from batch\n",
    "        x, y = batch\n",
    "\n",
    "        # Forward pass\n",
    "        logits = self(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = self.loss(logits, y)\n",
    "\n",
    "        # Compute accuracy\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        # Log validation loss and accuracy\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we've overridden the `training_step` and `validation_step` methods to include the logging of loss and accuracy metrics. The `self.log` method makes it easy to track these metrics during training and validation. Since `Application` is an extension of `LightningModule`, all the features and methods available in `LightningModule` are naturally available in your custom `Application` class as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySubclassOfImageClassifier:\n",
    "    defaults = (\n",
    "        Config()\n",
    "        .merge(None, MyImageClassifier.defaults)\n",
    "        .my_custom_parameter(42)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending Class Defaults with Config\n",
    "\n",
    "When building your own custom applications, you may want to extend the configurations of a parent class to include additional or modified settings. Deeplay's `Config` object provides a convenient `.merge()` method to facilitate this.\n",
    "\n",
    "#### Merging at the Root Level\n",
    "\n",
    "If you want to merge the parent class's defaults into your own at the root level, you can specify `None` as the first argument to `.merge()` like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySubclassOfImageClassifier:\n",
    "\n",
    "    defaults = (\n",
    "        Config()\n",
    "        .merge(None, MyImageClassifier.defaults)\n",
    "        .my_custom_parameter(42)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here, the `None` indicates that `MyImageClassifier.defaults` should be merged into `MySubclassOfImageClassifier`'s `defaults` at the root level.\n",
    "\n",
    "#### Merging Into a Specific Key\n",
    "\n",
    "Alternatively, if you want to merge the defaults under a specific key in your configuration, you can specify that key:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = (\n",
    "    Config()\n",
    "    .merge(\"parent_defaults\", MyImageClassifier.defaults)\n",
    "    .my_custom_parameter(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this example, `MyImageClassifier.defaults` will be merged under the key `parent_defaults` in the `defaults` configuration for `MySubclassOfImageClassifier`.\n",
    "\n",
    "This allows you to extend and customize configurations flexibly, while keeping the settings from the parent class accessible and organized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
