{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring Deeplay Objects\n",
    "\n",
    "The `.configure()` method permits you to configure Deeplay objects. You can combine it with selectors to target specific objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `.configure()` Method\n",
    "\n",
    "The `.configure()` method exists for all `DeeplayModule` objects. It works by changing the input parameters of the constructor of the class, and subsequently re-initializing the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (blocks): LayerList(\n",
      "    (0): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=10, out_features=20, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=20, out_features=30, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=30, out_features=40, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (3): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=40, out_features=5, bias=True)\n",
      "      (activation): Layer[Identity]()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mlp = dl.MultiLayerPerceptron(\n",
    "    in_features=10,\n",
    "    hidden_features=[20, 30, 40],\n",
    "    out_features=5,\n",
    ")\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (blocks): LayerList(\n",
      "    (0): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=10, out_features=20, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=20, out_features=30, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=30, out_features=40, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (3): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=40, out_features=5, bias=True)\n",
      "      (activation): Layer[Tanh]()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mlp.configure(out_activation=torch.nn.Tanh)\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `Layer` classes, the configure method will instead affect the constructor argument of the classtype of the layer. For example, `Layer(nn.Conv2d, 8, 8).configure(kernel_size=5)`. The first positional argument can be used to change the class type of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1)\n"
     ]
    }
   ],
   "source": [
    "layer = dl.Layer(\n",
    "    torch.nn.Conv2d, \n",
    "    in_channels=3, \n",
    "    out_channels=10, \n",
    "    kernel_size=1,\n",
    ")\n",
    "\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=2)\n"
     ]
    }
   ],
   "source": [
    "layer.configure(stride=2)\n",
    "\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer[ReLU]()\n"
     ]
    }
   ],
   "source": [
    "layer = dl.Layer(torch.nn.ReLU)\n",
    "\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer[LeakyReLU](negative_slope=0.1)\n"
     ]
    }
   ],
   "source": [
    "layer.configure(torch.nn.LeakyReLU, negative_slope=0.1)\n",
    "\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Selections\n",
    "\n",
    "Selections are a way to apply an operation or configuration to multiple classes at once. There is some special syntax, which is easier to understand through examples ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = dl.UNet2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32],\n",
    "    out_channels=10,\n",
    "    out_activation=torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use strings to select a direct child ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder',)]\n"
     ]
    }
   ],
   "source": [
    "selection = model[\"encoder\"]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use multiple strings to select multiple successive children ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks')]\n"
     ]
    }
   ],
   "source": [
    "selection = model[\"encoder\", \"blocks\"]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use the `|` operator to select multiple children at the same level ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder',), ('decoder',)]\n"
     ]
    }
   ],
   "source": [
    "selection = model[\"encoder|decoder\"]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use the `:` operator to select all children at the same level ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder',), ('bottleneck',), ('decoder',), ('skip',)]\n"
     ]
    }
   ],
   "source": [
    "selection = model[:]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use the `...` operator to select select all children at any level ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), ('encoder',), ('encoder', 'blocks'), ('encoder', 'blocks', '0'), ('encoder', 'blocks', '0', 'layer'), ('encoder', 'blocks', '0', 'activation'), ('encoder', 'blocks', '1'), ('encoder', 'blocks', '1', 'pool'), ('encoder', 'blocks', '1', 'layer'), ('encoder', 'blocks', '1', 'activation'), ('encoder', 'postprocess'), ('bottleneck',), ('bottleneck', 'blocks'), ('bottleneck', 'blocks', '0'), ('bottleneck', 'blocks', '0', 'pool'), ('bottleneck', 'blocks', '0', 'layer'), ('bottleneck', 'blocks', '0', 'activation'), ('bottleneck', 'blocks', '0', 'upsample'), ('decoder',), ('decoder', 'blocks'), ('decoder', 'blocks', '0'), ('decoder', 'blocks', '0', 'layer'), ('decoder', 'blocks', '0', 'activation'), ('decoder', 'blocks', '0', 'upsample'), ('decoder', 'blocks', '1'), ('decoder', 'blocks', '1', 'layer'), ('decoder', 'blocks', '1', 'activation'), ('decoder', 'preprocess'), ('skip',)]\n"
     ]
    }
   ],
   "source": [
    "# This selects all children of the model.\n",
    "selection = model[...]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks', '0', 'layer'), ('encoder', 'blocks', '1', 'layer'), ('bottleneck', 'blocks', '0', 'layer'), ('decoder', 'blocks', '0', 'layer'), ('decoder', 'blocks', '1', 'layer')]\n"
     ]
    }
   ],
   "source": [
    "# This selects only the children named \"layer\".\n",
    "selection = model[..., \"layer\"]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder',), ('encoder', 'blocks'), ('encoder', 'blocks', '0'), ('encoder', 'blocks', '0', 'layer'), ('encoder', 'blocks', '0', 'activation'), ('encoder', 'blocks', '1'), ('encoder', 'blocks', '1', 'pool'), ('encoder', 'blocks', '1', 'layer'), ('encoder', 'blocks', '1', 'activation'), ('encoder', 'postprocess')]\n"
     ]
    }
   ],
   "source": [
    "# This selects all children of the \"encoder\" child.\n",
    "selection = model[\"encoder\", ...] \n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks'), ('encoder', 'blocks', '0'), ('encoder', 'blocks', '0', 'layer'), ('encoder', 'blocks', '0', 'activation'), ('encoder', 'blocks', '1'), ('encoder', 'blocks', '1', 'pool'), ('encoder', 'blocks', '1', 'layer'), ('encoder', 'blocks', '1', 'activation'), ('bottleneck', 'blocks'), ('bottleneck', 'blocks', '0'), ('bottleneck', 'blocks', '0', 'pool'), ('bottleneck', 'blocks', '0', 'layer'), ('bottleneck', 'blocks', '0', 'activation'), ('bottleneck', 'blocks', '0', 'upsample'), ('decoder', 'blocks'), ('decoder', 'blocks', '0'), ('decoder', 'blocks', '0', 'layer'), ('decoder', 'blocks', '0', 'activation'), ('decoder', 'blocks', '0', 'upsample'), ('decoder', 'blocks', '1'), ('decoder', 'blocks', '1', 'layer'), ('decoder', 'blocks', '1', 'activation')]\n"
     ]
    }
   ],
   "source": [
    "# This selects all children at any level, \n",
    "# then it selects the children named \"blocks\", \n",
    "# finally it selects all children of the \"blocks\" children.\n",
    "selection = model[..., \"blocks\", ...]\n",
    "\n",
    "print(selection.list_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use the `#` operator to select a subset of previously selected children ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks', '0', 'layer'), ('encoder', 'blocks', '1', 'layer'), ('bottleneck', 'blocks', '0', 'layer')]\n"
     ]
    }
   ],
   "source": [
    "selection = model[..., \"layer#:3\"]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks', '1', 'layer'), ('bottleneck', 'blocks', '0', 'layer'), ('decoder', 'blocks', '0', 'layer')]\n"
     ]
    }
   ],
   "source": [
    "selection = model[..., \"layer#1:4\"]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('decoder', 'blocks', '1', 'layer')]\n"
     ]
    }
   ],
   "source": [
    "selection = model[..., \"layer#-1\"]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... use the `,` operator to select either of multiple selectors ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks', '0', 'layer'), ('decoder', 'blocks', '1', 'layer')]\n"
     ]
    }
   ],
   "source": [
    "selection = model[..., \"layer#0, layer#-1\"]\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... as an example select the first block of the encoder and change its kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=1, stride=1, padding=0)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model[..., \"layer#0\"].configure(kernel_size=1, padding=0)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering a Selection\n",
    "\n",
    "The selection can be filtered using the `.filter()`, `.hasattr()`, or `.isinstance()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = dl.UNet2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32],\n",
    "    out_channels=10,\n",
    "    out_activation=torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder',)]\n"
     ]
    }
   ],
   "source": [
    "selection = model[...].isinstance(dl.ConvolutionalEncoder2d)\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks', '0', 'activation'), ('encoder', 'blocks', '1', 'activation')]\n"
     ]
    }
   ],
   "source": [
    "selection = model[\"encoder\", ...].isinstance(torch.nn.ReLU)\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks', '0'), ('encoder', 'blocks', '1'), ('bottleneck', 'blocks', '0'), ('decoder', 'blocks', '0'), ('decoder', 'blocks', '1')]\n"
     ]
    }
   ],
   "source": [
    "selection = model[...].hasattr(\"pool\")  ### bugged. should not return decoder.\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder', 'blocks', '0'), ('encoder', 'blocks', '1'), ('bottleneck', 'blocks', '0'), ('decoder', 'blocks', '0'), ('decoder', 'blocks', '1')]\n"
     ]
    }
   ],
   "source": [
    "selection = model[...].hasattr(\"stride\")\n",
    "\n",
    "print(selection.list_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Methods to a Selection\n",
    "\n",
    "Any method can be applied to the selection, not just `.configure()`. This will either apply the method to all classes in the selection, or to the first class in the selection. You can choose which one by accessing the `.all` or `.first` attributes of the selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = dl.UNet2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32],\n",
    "    out_channels=10,\n",
    "    out_activation=torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model[..., \"layer\"].first.configure(kernel_size=5, padding=2)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model[..., \"activation\"].all.configure(torch.nn.Sigmoid)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "        (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "        (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=10)\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model[...].isinstance(dl.Conv2dBlock).all.normalized(torch.nn.BatchNorm2d)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "        (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "        (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=10)\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model[...].isinstance(torch.nn.BatchNorm2d).all \\\n",
    "    .initialize(dl.initializers.Constant(weight=1, bias=0))\n",
    "    \n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_dlcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
