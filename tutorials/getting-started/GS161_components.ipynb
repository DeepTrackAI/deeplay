{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deeplay Components\n",
    "\n",
    "Deeplay components are usually constructed by combining multiple blocks. As opposed to models, they don't have a default architecture. Instead, the properties of the architecture (including the number of features in each layer) are passed as arguments to the constructor. This makes components more flexible than models, but also more complex to use. Models are usually constructed by combining multiple components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Components Available in Deeplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MultiLayerPerceptron`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (blocks): LayerList(\n",
      "    (0): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=10, out_features=20, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=20, out_features=30, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=30, out_features=40, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (3): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=40, out_features=5, bias=True)\n",
      "      (activation): Layer[Tanh]()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mlp = dl.MultiLayerPerceptron(\n",
    "    in_features=10,\n",
    "    hidden_features=[20, 30, 40],\n",
    "    out_features=5,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ConvolutionalNeuralNetwork`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalNeuralNetwork(\n",
      "  (blocks): LayerList(\n",
      "    (0): Conv2dBlock(\n",
      "      (pool): Layer[AvgPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
      "      (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (1): Conv2dBlock(\n",
      "      (pool): Layer[AvgPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
      "      (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (2): Conv2dBlock(\n",
      "      (pool): Layer[AvgPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
      "      (normalization): Layer[BatchNorm2d](num_features=64)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (3): Conv2dBlock(\n",
      "      (pool): Layer[AvgPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=64, out_channels=10, kernel_size=3, stride=2, padding=1)\n",
      "      (normalization): Layer[BatchNorm2d](num_features=10)\n",
      "      (activation): Layer[Tanh]()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = dl.ConvolutionalNeuralNetwork(\n",
    "    in_channels=3,\n",
    "    hidden_channels=[16, 32, 64],\n",
    "    out_channels=10,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    "    pool=dl.Layer(torch.nn.MaxPool2d, kernel_size=2),\n",
    ")\n",
    "cnn.normalized(\n",
    "    dl.Layer(torch.nn.BatchNorm2d), \n",
    "    after_last_layer=True,\n",
    "    mode=\"insert\", \n",
    "    after=\"layer\",\n",
    ")\n",
    "cnn.strided(2, apply_to_first=True)\n",
    "cnn.pooled(\n",
    "    dl.Layer(torch.nn.AvgPool2d, kernel_size=2),\n",
    "    before_first=True,\n",
    ")\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ConvolutionalEncoder2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalEncoder2d(\n",
      "  (blocks): LayerList(\n",
      "    (0): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
      "      (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (1): Conv2dBlock(\n",
      "      (pool): Layer[AvgPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
      "      (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (2): Conv2dBlock(\n",
      "      (pool): Layer[AvgPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
      "      (normalization): Layer[BatchNorm2d](num_features=64)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (3): Conv2dBlock(\n",
      "      (pool): Layer[AvgPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=64, out_channels=10, kernel_size=3, stride=2, padding=1)\n",
      "      (normalization): Layer[BatchNorm2d](num_features=10)\n",
      "      (activation): Layer[Tanh]()\n",
      "    )\n",
      "  )\n",
      "  (postprocess): Layer[Identity]()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "enc = dl.ConvolutionalEncoder2d(\n",
    "    in_channels=3,\n",
    "    hidden_channels=[16, 32, 64],\n",
    "    out_channels=10,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "enc.strided(stride=2, apply_to_first_layer=True, apply_to_last_layer=True) \\\n",
    "    .pooled(dl.Layer(torch.nn.AvgPool2d, kernel_size=2)) \\\n",
    "    .normalized(dl.Layer(torch.nn.BatchNorm2d), after_last_layer=True, \n",
    "                mode=\"insert\", after=\"layer\")\n",
    "\n",
    "print(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ConvolutionalDecoder2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalDecoder2d(\n",
      "  (blocks): LayerList(\n",
      "    (0): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=10, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (upsample): Layer[Upsample](scale_factor=2)\n",
      "    )\n",
      "    (1): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (upsample): Layer[Upsample](scale_factor=2)\n",
      "    )\n",
      "    (2): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (upsample): Layer[Upsample](scale_factor=2)\n",
      "    )\n",
      "    (3): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=16, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[Tanh]()\n",
      "      (upsample): Layer[Upsample](scale_factor=2)\n",
      "    )\n",
      "  )\n",
      "  (preprocess): Layer[Identity]()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dec = dl.ConvolutionalDecoder2d(\n",
    "    in_channels=10,\n",
    "    hidden_channels=[64, 32, 16],\n",
    "    out_channels=3,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "dec.upsampled(\n",
    "    dl.Layer(torch.nn.Upsample, scale_factor=2),\n",
    "    apply_to_last_layer=True, \n",
    ")\n",
    "\n",
    "print(dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ConvolutionalEncoderDecoder2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoderDecoder2d(\n",
       "  (encoder): ConvolutionalEncoder2d(\n",
       "    (blocks): LayerList(\n",
       "      (0): Conv2dBlock(\n",
       "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
       "        (activation): Layer[ReLU]()\n",
       "      )\n",
       "      (1): Conv2dBlock(\n",
       "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
       "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
       "        (activation): Layer[ReLU]()\n",
       "      )\n",
       "      (2): Conv2dBlock(\n",
       "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
       "        (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
       "        (activation): Layer[ReLU]()\n",
       "      )\n",
       "    )\n",
       "    (postprocess): Layer[Identity]()\n",
       "  )\n",
       "  (bottleneck): ConvolutionalNeuralNetwork(\n",
       "    (blocks): LayerList(\n",
       "      (0): Conv2dBlock(\n",
       "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
       "        (layer): Layer[Conv2d](in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
       "        (activation): Layer[ReLU]()\n",
       "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=64, out_channels=64)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConvolutionalDecoder2d(\n",
       "    (blocks): LayerList(\n",
       "      (0): Conv2dBlock(\n",
       "        (layer): Layer[Conv2d](in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
       "        (activation): Layer[ReLU]()\n",
       "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
       "      )\n",
       "      (1): Conv2dBlock(\n",
       "        (layer): Layer[Conv2d](in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
       "        (activation): Layer[ReLU]()\n",
       "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
       "      )\n",
       "      (2): Conv2dBlock(\n",
       "        (layer): Layer[Conv2d](in_channels=16, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
       "        (activation): Layer[Tanh]()\n",
       "      )\n",
       "    )\n",
       "    (preprocess): Layer[Identity]()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encdec = dl.ConvolutionalEncoderDecoder2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    decoder_channels=None,\n",
    "    out_channels=3,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "\n",
    "encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalEncoderDecoder2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (2): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): Layer[Identity]()\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (2): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encdec = dl.ConvolutionalEncoderDecoder2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    decoder_channels=[32, 16],\n",
    "    bottleneck_channels=[],\n",
    "    out_channels=3,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "\n",
    "print(encdec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalEncoderDecoder2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (2): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=64, out_channels=64)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (2): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encdec = dl.ConvolutionalEncoderDecoder2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    bottleneck_channels=None,\n",
    "    out_channels=3,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "\n",
    "print(encdec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `UNet2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (2): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=64, out_channels=64)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[LazyConv2d](out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[LazyConv2d](out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (2): Conv2dBlock(\n",
      "        (layer): Layer[LazyConv2d](out_channels=3, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Add()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "unet = dl.UNet2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    bottleneck_channels=None,\n",
    "    decoder_channels=[32, 16],\n",
    "    out_channels=3,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    "    skip=dl.ops.Add(),\n",
    ")\n",
    "\n",
    "print(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (2): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=64, out_channels=64)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=128, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=32, out_channels=32)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0, in_channels=16, out_channels=16)\n",
      "      )\n",
      "      (2): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "unet = dl.UNet2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32, 64],\n",
    "    bottleneck_channels=None,\n",
    "    decoder_channels=[32, 16],\n",
    "    out_channels=3,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "\n",
    "print(unet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RecurrentNeuralNetwork`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecurrentNeuralNetwork(\n",
      "  (blocks): LayerList(\n",
      "    (0): Sequence1dBlock(\n",
      "      (layer): Layer[LSTM](input_size=10, hidden_size=20, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (1): Sequence1dBlock(\n",
      "      (layer): Layer[LSTM](input_size=20, hidden_size=30, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (2): Sequence1dBlock(\n",
      "      (layer): Layer[LSTM](input_size=30, hidden_size=40, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (3): Sequence1dBlock(\n",
      "      (layer): Layer[LSTM](input_size=40, hidden_size=5, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = dl.RecurrentNeuralNetwork(\n",
    "    in_features=10,\n",
    "    hidden_features=[20, 30, 40],\n",
    "    out_features=5,\n",
    "    batch_first=True,\n",
    "    return_cell_state=False,\n",
    ")\n",
    "rnn.bidirectional()\n",
    "\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GraphConvolutionalNeuralNetwork`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphConvolutionalNeuralNetwork(\n",
      "  (normalize): Layer[sparse_laplacian_normalization]()\n",
      "  (blocks): LayerList(\n",
      "    (0): TransformPropagateUpdate(\n",
      "      (transform): Layer[Linear](in_features=10, out_features=20)\n",
      "      (propagate): Layer[Propagate]()\n",
      "      (update): Layer[ReLU]()\n",
      "    )\n",
      "    (1): TransformPropagateUpdate(\n",
      "      (transform): Layer[Linear](in_features=20, out_features=30)\n",
      "      (propagate): Layer[Propagate]()\n",
      "      (update): Layer[ReLU]()\n",
      "    )\n",
      "    (2): TransformPropagateUpdate(\n",
      "      (transform): Layer[Linear](in_features=30, out_features=40)\n",
      "      (propagate): Layer[Propagate]()\n",
      "      (update): Layer[ReLU]()\n",
      "    )\n",
      "    (3): TransformPropagateUpdate(\n",
      "      (transform): Layer[Linear](in_features=40, out_features=5)\n",
      "      (propagate): Layer[Propagate]()\n",
      "      (update): Layer[Tanh]()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gcnn = dl.GraphConvolutionalNeuralNetwork(\n",
    "    in_features=10,\n",
    "    hidden_features=[20, 30, 40],\n",
    "    out_features=5,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "\n",
    "print(gcnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MessagePassingNeuralNetwork`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MessagePassingNeuralNetwork(\n",
      "  (blocks): LayerList(\n",
      "    (0): TransformPropagateUpdate(\n",
      "      (transform): Transform(\n",
      "        (combine): Cat()\n",
      "        (layer): Layer[LazyLinear](out_features=20)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (propagate): Sum()\n",
      "      (update): Update(\n",
      "        (combine): Cat()\n",
      "        (layer): Layer[LazyLinear](out_features=20)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (1): TransformPropagateUpdate(\n",
      "      (transform): Transform(\n",
      "        (combine): Cat()\n",
      "        (layer): Layer[LazyLinear](out_features=30)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (propagate): Sum()\n",
      "      (update): Update(\n",
      "        (combine): Cat()\n",
      "        (layer): Layer[LazyLinear](out_features=30)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (2): TransformPropagateUpdate(\n",
      "      (transform): Transform(\n",
      "        (combine): Cat()\n",
      "        (layer): Layer[LazyLinear](out_features=40)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "      (propagate): Sum()\n",
      "      (update): Update(\n",
      "        (combine): Cat()\n",
      "        (layer): Layer[LazyLinear](out_features=40)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (3): TransformPropagateUpdate(\n",
      "      (transform): Transform(\n",
      "        (combine): Cat()\n",
      "        (layer): Layer[LazyLinear](out_features=5)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "      (propagate): Sum()\n",
      "      (update): Update(\n",
      "        (combine): Cat()\n",
      "        (layer): Layer[LazyLinear](out_features=5)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mpgnn = dl.MessagePassingNeuralNetwork(\n",
    "    hidden_features=[20, 30, 40],\n",
    "    out_features=5,\n",
    "    out_activation=dl.Layer(torch.nn.Tanh),\n",
    ")\n",
    "\n",
    "print(mpgnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_dlcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
