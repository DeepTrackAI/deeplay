{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing Templates and Components\n",
    "\n",
    "**Why Customize?**\n",
    "\n",
    "While Deeplay provides a robust set of pre-defined templates and components, there may be cases where you'd like to customize these to better suit your specific problem. Customization can range from minor changes to existing templates to creating entirely new components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization using Config\n",
    "\n",
    "**Decoding Automatic Summaries**\n",
    "\n",
    "When you print your model using `print(model)`, `deeplay` will provide an automatic summary that shows the hierarchical structure of the model. Your `Config` object should mirror this hierarchy, allowing you to easily set or modify specific attributes and layers within the model. For example, let's look at the initial lines of the `ImageClassifier` summary:\n",
    "\n",
    "```python\n",
    "ImageClassifier(\n",
    "  (num_classes): 10\n",
    "  (backbone): ImageToVectorEncoder(\n",
    "    (depth): 4\n",
    "    (input_block): Template(\n",
    "      (layer): LazyConv2d(0, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (activation): ReLU()\n",
    "    )\n",
    "    (encoder_blocks): ModuleList(\n",
    "      (0): Template(\n",
    "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        (layer): LazyConv2d(0, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        (activation): ReLU()\n",
    "      )\n",
    "    ... continues\n",
    "```\n",
    "\n",
    "Pay attention to the names within parentheses â€” `backbone`, `depth`, `input_block`, `encoder_blocks`, `0`, `layer` and more. To change the `kernel_size` attribute, you can create a `Config` object that mimics this structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay import Config \n",
    "\n",
    "config = Config().backbone.encoder_blocks[0].layer.kernel_size(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you want to update many blocks at once, you can use slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config().backbone.encoder_blocks[0:4].layer.kernel_size(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you want to update all blocks at once, you can omit the indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config().backbone.encoder_blocks.layer.kernel_size(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Just like you can update attributes of the layers, you can also change the type of layers themselves. For instance, to change the activation function to `LeakyReLU` for all blocks, you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "config = Config().backbone.encoder_blocks.activation(nn.LeakyReLU, negative_slope=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you to easily swap out modules and tune the model to better fit your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Customization using Templates\n",
    "\n",
    "**Switching to a More Complex Block Design**\n",
    "\n",
    "Let's continue from our previous example. Deeplay allows you to define the structure of your blocks via templates. A template specifies the sequence and type of layers you want to stack together in a block. Here's how you can define a new template to include a batch normalization layer in each block:\n",
    "\n",
    "This level of customization opens up a wide array of possibilities, allowing you to quickly experiment with various architectures while keeping the rest of your setup intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from deeplay import Layer, Config\n",
    "\n",
    "block_template = Layer(\"layer\") >> Layer(\"activation\") >> Layer(\"normalization\") >> Layer(\"pool\")\n",
    "\n",
    "config = (\n",
    "    Config()\n",
    "    .backbone.encoder_blocks(block_template)\n",
    "    .backbone.encoder_blocks.normalization(nn.LazyBatchNorm2d)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The string you pass into the `Layer` object directly corresponds to the name you'll use in the `Config` object. This is how Deeplay knows what layer you're trying to customize or add. For example, the `\"normalization\"` string in `Layer(\"normalization\")` is what you'll use to set the normalization layer type in the config, as in `.backbone.blocks.normalization(nn.LazyBatchNorm2d)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It's worth noting that `normalization` wasn't a default component in the original `ImageClassifier`. By adding* it to our custom `block_template`, we've effectively expanded the architecture of the model. After adding a new layer to a template, you should also specify its settings in the Config. Here, we're setting it to use `nn.LazyBatchNorm2d`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Pretrained Torch Modules\n",
    "\n",
    "**Incorporate Pretrained Models for a Quick Start**\n",
    "\n",
    "Deeplay allows for seamless integration of pretrained PyTorch models, making it incredibly easy to leverage existing architectures. Take for example a pretrained ResNet-18 model from torchvision:\n",
    "\n",
    "This offers a quick and straightforward way to benefit from well-established architectures while still maintaining the flexibility that Deeplay provides.\n",
    "\n",
    "Is this in line with what you're looking for? Feel free to make edits or suggest revisions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifier(\n",
      "  (num_classes): 10\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): Identity()\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (head): CategoricalClassificationHead(\n",
      "    (num_classes): 10\n",
      "    (output): Template(\n",
      "      (layer): LazyLinear(in_features=0, out_features=10, bias=True)\n",
      "      (activation): LogSoftmax(dim=None)\n",
      "    )\n",
      "  )\n",
      "  (loss): NLLLoss()\n",
      "  (val_accuracy): Accuracy()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\GU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "from deeplay import ImageClassifier, Config\n",
    "\n",
    "backbone = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Remove the pooling and fully connected layers as they are not needed\n",
    "backbone.avgpool = nn.Identity()\n",
    "backbone.fc = nn.Identity()\n",
    "\n",
    "classifier = ImageClassifier.from_config(\n",
    "    Config()\n",
    "    .num_classes(10)\n",
    "    .backbone(backbone)\n",
    ")\n",
    "\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here, we directly use the pretrained ResNet-18 model as the `backbone` in our `ImageClassifier`. Note that you might need to remove or adapt certain layers, like we did with the average pooling (`avgpool`) and fully connected (`fc`) layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Non-Deeplay modules cannot be further customized using Deeplay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
