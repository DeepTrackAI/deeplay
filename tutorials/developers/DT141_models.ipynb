{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Implementing a Model\n",
        "\n",
        "Models are broadly defined as classes that represent a specific architecture, such as `ResNet18`. Unlike components, they are generally not as flexible in terms of input arguments, and it should be possible to pass them directly to applications. Models are designed to be easy to use and require minimal configuration to get started. They are also designed to be easily extensible, so that you can add new features without having to modify the existing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What Should Be Implemented as a Model?\n",
        "\n",
        "The first step is to ensure that what you want to implement is actually a model.\n",
        "Most models are composed of a few named components (for example, `ConvolutionalNeuralNetwork`), and generally intended as a complete transformation from input to output for a given task.\n",
        "\n",
        "Most models are standard neural networks with exact architectures (like `ResNet50`), but models can also be more general architectures (like a `RecurrentModel`). \n",
        "\n",
        "Unlike components, models generally have a rigid structure. It is not expected that\n",
        "the number of blocks or the sizes of the layers can be defined in the input arguments. However, if possible, the input and output shapes should be flexible.\n",
        "\n",
        "Examples of models are `ViT`, `CycleGANGenerator`, `ResNet`, `RecurrentModel`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What Should a Model Contain?\n",
        "\n",
        "Generally, a model should define an `.__init__()` method that takes all the necessary arguments to define the model and a `.forward()` method that defines the forward pass of the model.\n",
        "\n",
        "Optimally, a model should have a forward pass as simple as possible. A fully sequential forward pass is optimal.\n",
        "This is because any hard-coded structure in the forward pass limits the flexibility of the model. For example, if the forward pass is defined as `self.conv1(x) + self.conv2(x)`, then it is not possible to replace `self.conv1` and `self.conv2` with a single `self.conv` without modifying the model.\n",
        "\n",
        "Moreover, the model architecture should in almost all cases be defined purely out of components and operations. Try to limit direct calls to `torch.nn` modules and `blocks`. This is because the `torch.nn` modules are not as flexible as the Deeplay components and operations. If components do not exist for the desired architecture, then it is a good idea to create a new component and add it to the `components` folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementing a Model\n",
        "\n",
        "Here, you'll see the steps you should follow to implement a model in Deeplay. You'll do this implementing the `ResNet18` model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Create a New File\n",
        "\n",
        "The first step is to create a new file in the `deeplay/models` directory. It\n",
        "can be in a deeper subdirectory if it makes sense.\n",
        "\n",
        "**The base class.** \n",
        "Models generally don't have a fixed base class. Sometimes it makes sense to subclass an existing model, but it is not necessary. It is in some cases possible to subclass a component, if the model is simply that component with some additional layers or with an exact architecture. If neither are applicable, use `DeeplayModule` as the base class.\n",
        "\n",
        "**Styled components and blocks.**\n",
        "Special for the implementation of models is the expectation to used styled components\n",
        "and blocks where possible. This is to ensure that the modules can be reused in other\n",
        "models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2a. Implement the ResNet18 Block\n",
        "\n",
        "First, implement the ResNet block as a styled block. It should be implemented\n",
        "in the same file as the model.\n",
        "\n",
        "**NOTE:** The style should have a small docstring, just like in the case of a method. The first argument should not be documented (just as `self` is not documented in methods)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from deeplay.blocks import Conv2dBlock\n",
        "\n",
        "@Conv2dBlock.register_style\n",
        "def resnet(block: Conv2dBlock, stride: int = 1) -> None:\n",
        "    \"\"\"ResNet style block composed of two residual blocks.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        Stride of the first block, by default 1\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. Create two blocks.\n",
        "    block.multi(2)\n",
        "\n",
        "    # 2. Make the two blocks.\n",
        "    block.blocks[0].style(\"residual\", order=\"lnaln|a\")\n",
        "    block.blocks[1].style(\"residual\", order=\"lnaln|a\")\n",
        "\n",
        "    # 3. If stride > 1, stride first block and add normalization to shortcut.\n",
        "    if stride > 1:\n",
        "        block.blocks[0].strided(stride)\n",
        "        block.blocks[0].shortcut_start.normalized()\n",
        "\n",
        "    # 4. Remove the pooling layer if it exists.\n",
        "    block[...].isinstance(Conv2dBlock).all.remove(\"pool\", allow_missing=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now instatiate this block and verify its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conv2dBlock(\n",
            "  (blocks): Sequential(\n",
            "    (0-1): 2 x Conv2dBlock(\n",
            "      (shortcut_start): Conv2dBlock(\n",
            "        (layer): Layer[Identity](in_channels=16, out_channels=16, kernel_size=1, stride=1, padding=0)\n",
            "      )\n",
            "      (blocks): Sequential(\n",
            "        (0): Conv2dBlock(\n",
            "          (layer): Layer[Conv2d](in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
            "          (normalization): Layer[BatchNorm2d](num_features=16)\n",
            "          (activation): Layer[ReLU]()\n",
            "        )\n",
            "        (1): Conv2dBlock(\n",
            "          (layer): Layer[Conv2d](in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
            "          (normalization): Layer[BatchNorm2d](num_features=16)\n",
            "        )\n",
            "      )\n",
            "      (shortcut_end): Add()\n",
            "      (activation): Layer[ReLU]()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "block = Conv2dBlock(16, 16).style(\"resnet\")\n",
        "\n",
        "print(block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2b. Implement the ResNet18 Input Block\n",
        "\n",
        "The input block is slightly different from the normal block. You can implement also this block as a styled block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from deeplay.external.layer import Layer\n",
        "import torch.nn as nn\n",
        "\n",
        "@Conv2dBlock.register_style\n",
        "def resnet18_input(block: Conv2dBlock) -> None:\n",
        "    \"\"\"ResNet18 input block.\n",
        "\n",
        "    The block used on the input of the ResNet18 architecture.\n",
        "    \"\"\"\n",
        "    \n",
        "    block.configure(kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    block.normalized(mode=\"insert\", after=\"layer\")\n",
        "    block.activated(\n",
        "        Layer(nn.ReLU, inplace=True), mode=\"insert\", after=\"normalization\",\n",
        "    )\n",
        "    pool = Layer(\n",
        "        nn.MaxPool2d, kernel_size=3, stride=2, padding=1, ceil_mode=False, \n",
        "        dilation=1,\n",
        "    )\n",
        "    block.pooled(pool, mode=\"append\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also in this case, you can instantiate this block and verify its architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conv2dBlock(\n",
            "  (layer): Layer[Conv2d](in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
            "  (normalization): Layer[BatchNorm2d](num_features=64)\n",
            "  (activation): Layer[ReLU](inplace=True)\n",
            "  (pool): Layer[MaxPool2d](kernel_size=3, stride=2, padding=1, ceil_mode=False, dilation=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "block = Conv2dBlock(3, 64).style(\"resnet18_input\")\n",
        "\n",
        "print(block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2c. Implement the ResNet18 Backbone\n",
        "\n",
        "The backbone is a styled component, and should be implemented in the same file as the\n",
        "model. As it is a convolutional encoder, you can style a `ConvolutionalEncoder2d` component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from deeplay.components import ConvolutionalEncoder2d\n",
        "from deeplay.initializers import Kaiming, Constant\n",
        "\n",
        "@ConvolutionalEncoder2d.register_style\n",
        "def resnet18(\n",
        "    encoder: ConvolutionalEncoder2d, \n",
        "    pool_output: bool = True,\n",
        "    set_hidden_channels: bool = False,\n",
        ") -> None: \n",
        "    \"\"\"ResNet18 backbone.\n",
        "\n",
        "    Styles a ConvolutionalEncoder2d to have the ResNet18 architecture.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    pool_output : bool\n",
        "        Whether to append a pooling layer at the end of the encoder, by default \n",
        "        True.\n",
        "    set_hidden_channels : bool\n",
        "        Whether to set the hidden channels to the default ResNet18 values, by \n",
        "        default False.\n",
        "    \"\"\"\n",
        "\n",
        "    if set_hidden_channels:\n",
        "        encoder.configure(hidden_channels=[64, 64, 128, 256])\n",
        "\n",
        "    # 1. Style the first block.\n",
        "    encoder.blocks[0].style(\"resnet18_input\")\n",
        "\n",
        "    # 2. The second block does not have a stride.\n",
        "    encoder.blocks[1].style(\"resnet\", stride=1)\n",
        "\n",
        "    # 3. The rest of the blocks have a stride of 2.\n",
        "    encoder[\"blocks\", 2:].hasattr(\"style\").all.style(\"resnet\", stride=2)\n",
        "\n",
        "    # 4. Initialize the weights.\n",
        "    encoder.initialize(Kaiming(targets=(nn.Conv2d,)))\n",
        "    encoder.initialize(Constant(targets=(nn.BatchNorm2d,)))\n",
        "\n",
        "    # 5. Set postprocess to pool the output if needed.\n",
        "    if pool_output:\n",
        "        encoder.postprocess.configure(nn.AdaptiveAvgPool2d, output_size=(1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now instantiate the backbone and print out its architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvolutionalEncoder2d(\n",
            "  (blocks): LayerList(\n",
            "    (0): Conv2dBlock(\n",
            "      (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=7, stride=2, padding=3)\n",
            "      (normalization): Layer[BatchNorm2d](num_features=16)\n",
            "      (activation): Layer[ReLU](inplace=True)\n",
            "      (pool): Layer[MaxPool2d](kernel_size=3, stride=2, padding=1, ceil_mode=False, dilation=1)\n",
            "    )\n",
            "    (1): Conv2dBlock(\n",
            "      (blocks): Sequential(\n",
            "        (0): Conv2dBlock(\n",
            "          (shortcut_start): Conv2dBlock(\n",
            "            (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=1, stride=1, padding=0)\n",
            "          )\n",
            "          (blocks): Sequential(\n",
            "            (0): Conv2dBlock(\n",
            "              (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
            "              (normalization): Layer[BatchNorm2d](num_features=32)\n",
            "              (activation): Layer[ReLU]()\n",
            "            )\n",
            "            (1): Conv2dBlock(\n",
            "              (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
            "              (normalization): Layer[BatchNorm2d](num_features=32)\n",
            "            )\n",
            "          )\n",
            "          (shortcut_end): Add()\n",
            "          (activation): Layer[ReLU]()\n",
            "        )\n",
            "        (1): Conv2dBlock(\n",
            "          (shortcut_start): Conv2dBlock(\n",
            "            (layer): Layer[Identity](in_channels=32, out_channels=32, kernel_size=1, stride=1, padding=0)\n",
            "          )\n",
            "          (blocks): Sequential(\n",
            "            (0): Conv2dBlock(\n",
            "              (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
            "              (normalization): Layer[BatchNorm2d](num_features=32)\n",
            "              (activation): Layer[ReLU]()\n",
            "            )\n",
            "            (1): Conv2dBlock(\n",
            "              (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
            "              (normalization): Layer[BatchNorm2d](num_features=32)\n",
            "            )\n",
            "          )\n",
            "          (shortcut_end): Add()\n",
            "          (activation): Layer[ReLU]()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (postprocess): Layer[AdaptiveAvgPool2d](output_size=(1, 1))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "backbone = ConvolutionalEncoder2d(3, [16], 32).style(\"resnet18\", pool_output=True)\n",
        "\n",
        "print(backbone)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2d. Implement the ResNet18 Model\n",
        "\n",
        "You can now finally implement the `ResNet18` model by subclassing `DeeplayModule`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from deeplay.module import DeeplayModule\n",
        "from deeplay.components import MultiLayerPerceptron\n",
        "\n",
        "class ResNet18(DeeplayModule):\n",
        "\n",
        "    def __init__(self, in_channels=3, latent_channels=512, num_classes=1000):\n",
        "        self.backbone = ConvolutionalEncoder2d(\n",
        "            in_channels, \n",
        "            [64, 64, 128, 256, 512], \n",
        "            latent_channels\n",
        "        )\n",
        "        self.backbone.style(\"resnet18\", pool_output=True)\n",
        "\n",
        "        self.head = MultiLayerPerceptron(latent_channels, [], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Add Annotations\n",
        "\n",
        "It's important to add annotations to the class and methods to ensure that the\n",
        "user knows what to expect. This is also useful for the IDE to provide \n",
        "autocomplete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class ResNet18(DeeplayModule):\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_channels: int = 3, \n",
        "        latent_channels: int = 512, \n",
        "        num_classes: int = 1000,\n",
        "    ) -> None: \n",
        "        self.backbone = ConvolutionalEncoder2d(\n",
        "            in_channels, \n",
        "            [64, 64, 128, 256, 512], \n",
        "            latent_channels\n",
        "        )\n",
        "        self.backbone.style(\"resnet18\", pool_output=True)\n",
        "\n",
        "        self.head = MultiLayerPerceptron(latent_channels, [], num_classes)\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        x: torch.Tensor,  \n",
        "    ) -> torch.Tensor: \n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Document the Model\n",
        "\n",
        "The next step is to document the model. This should include a description of \n",
        "the model, the input and output shapes, and the arguments that can be passed to\n",
        "the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNet18(DeeplayModule):\n",
        "    \"\"\"A ResNet18 model.\n",
        "\n",
        "    A ResNet18 model composed of a ConvolutionalEncoder2d backbone and a \n",
        "    MultiLayerPerceptron head.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : int\n",
        "        The number of input channels, by default 3.\n",
        "    latent_channels : int\n",
        "        The number of latent channels (at the end of the backbone), by default \n",
        "        512.\n",
        "    num_classes : int\n",
        "        The number of classes, by default 1000.\n",
        "    \n",
        "    Attributes\n",
        "    ----------\n",
        "    backbone : ConvolutionalEncoder2d\n",
        "        The backbone of the model.\n",
        "    head : MultiLayerPerceptron\n",
        "        The head of the model. By default a simple linear layer.\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    x : torch.Tensor\n",
        "        The input tensor of shape (N, in_channels, H, W).\n",
        "        Where N is the batch size, in_channels is the number of input channels,\n",
        "        H is the height, and W is the width.\n",
        "        H and W should be at least 33, but ideally 224.\n",
        "\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "    y : torch.Tensor\n",
        "        The output tensor of shape (N, num_classes).\n",
        "        Where N is the batch size and num_classes is the number of classes.\n",
        "\n",
        "    Evaluation\n",
        "    ----------\n",
        "    ```python\n",
        "    x = backbone(x)\n",
        "    x = head(x)\n",
        "    ```\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> model = ResNet18(3, 512, 1000).build()\n",
        "    >>> x = torch.randn(4, 3, 224, 224)\n",
        "    >>> y = model(x)\n",
        "    >>> y.shape\n",
        "    torch.Size([4, 1000])\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__( \n",
        "        self, \n",
        "        in_channels: int = 3, \n",
        "        latent_channels: int = 512, \n",
        "        num_classes: int = 1000,\n",
        "    ) -> None: \n",
        "        self.backbone = ConvolutionalEncoder2d(\n",
        "            in_channels, \n",
        "            [64, 64, 128, 256, 512], \n",
        "            latent_channels\n",
        "        )\n",
        "        self.backbone.style(\"resnet18\", pool_output=True)\n",
        "\n",
        "        self.head = MultiLayerPerceptron(latent_channels, [], num_classes)\n",
        "\n",
        "    def forward( \n",
        "        self, \n",
        "        x: torch.Tensor,  \n",
        "    ) -> torch.Tensor:   \n",
        "        \"\"\"Forward pass of the model.\n",
        "        \n",
        "        Evaluates `backbone` and `head` sequentially.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            The input tensor of shape (N, in_channels, H, W).\n",
        "            Where N is the batch size, in_channels is the number of input channels,\n",
        "            H is the height, and W is the width.\n",
        "            H and W should be at least 33, but ideally 224.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The output tensor of shape (N, num_classes).\n",
        "            Where N is the batch size and num_classes is the number of classes.\n",
        "        \"\"\"\n",
        "\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
