{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working with Deeplay Models\n",
        "\n",
        "Models are broadly defined as classes that represent a specific architecture, such as a ResNet18. Unlike components, they are generally not as flexible in terms of input arguments, and it should be possible to pass them directly to applications. Models are designed to be easy to use and require minimal configuration to get started. They are also designed to be easily extensible, so that you can add new features without having to modify the existing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is There in a Model?\n",
        "\n",
        "Generally, a model should define an `.__init__()` method that takes all the necessary arguments to define the model and a `.forward()` method that defines the forward pass of the model.\n",
        "\n",
        "Optimally, a model should have a forward pass as simple as possible. A fully sequential forward pass is optimal.\n",
        "This is because any hard-coded structure in the forward pass limits the flexibility of the model. For example, if the forward pass is defined as `self.conv1(x) + self.conv2(x)`, then it is not possible to replace `self.conv1` and `self.conv2` with a single `self.conv` without modifying the model.\n",
        "\n",
        "Moreover, the model architecture should in almost all cases be defined purely out of components and operations. Try to limit direct calls to `torch.nn` modules and `blocks`. This is because the `torch.nn` modules are not as flexible as the Deeplay components and operations. If components do not exist for the desired architecture, then it is a good idea to create a new component and add it to the `components` folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Managing Unknown Tensor Sizes\n",
        "\n",
        "Tensorflow, and by extension Keras, allows for unknown tensor sizes thanks to the graph structure. This is not possible in PyTorch.\n",
        "\n",
        "If you need to support unknown tensor sizes, you can use the `lazy` module. This module allows for unknown tensor sizes by delaying the\n",
        "construction of the model until the first forward pass. This is not optimal, so use it sparingly. Examples are `nn.LazyConv2d` and `nn.LazyLinear`.\n",
        "\n",
        "If a model requires unknown tensor sizes, it is heavily encouraged to define the `.validate_after_build()` method, which should call the forward pass with a small input to validate that the model can be built. This will instantiate the lazy modules directly, allowing for a more user-friendly experience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**TODO** where do the next cells belong?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImageClassifier(\n",
              "  (model): Sequential(\n",
              "    (0): ConvolutionalEncoder2d(\n",
              "      (blocks): LayerList(\n",
              "        (0): Conv2dBlock(\n",
              "          (layer): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (1): Conv2dBlock(\n",
              "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (layer): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (2): Conv2dBlock(\n",
              "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (layer): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (3): Conv2dBlock(\n",
              "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (layer): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): Identity()\n",
              "        )\n",
              "      )\n",
              "      (postprocess): Identity()\n",
              "    )\n",
              "    (1): AdaptiveAvgPool2d(output_size=1)\n",
              "    (2): MultiLayerPerceptron(\n",
              "      (blocks): LayerList(\n",
              "        (0): LinearBlock(\n",
              "          (layer): Linear(in_features=128, out_features=10, bias=True)\n",
              "          (activation): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import deeplay as dl\n",
        "import torch.nn as nn\n",
        "\n",
        "net = dl.Sequential(\n",
        "    dl.ConvolutionalEncoder2d(1, [16, 32, 64], 128),\n",
        "    dl.Layer(nn.AdaptiveAvgPool2d, 1),\n",
        "    dl.MultiLayerPerceptron(128, [], 10)\n",
        ")\n",
        "\n",
        "class ImageClassifier(dl.Application):\n",
        "\n",
        "    model: nn.Module\n",
        "\n",
        "    def __init__(self, model: nn.Module):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "classifier = ImageClassifier(net).create()\n",
        "classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we allow the user to set the optimizer. Note that we are using the `create_optimizer_with_params` method to create the optimizer. We also use Adam as the default optimizer. It is better to set the default value of the optimizer to `None` and then set it to Adam in the `__init__` method. This is because the optimizer is a mutable object, and setting it to a default value of `Adam()` will cause all instances of the class to share the same optimizer object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImageClassifier(\n",
              "  (model): Sequential(\n",
              "    (0): ConvolutionalEncoder2d(\n",
              "      (blocks): LayerList(\n",
              "        (0): Conv2dBlock(\n",
              "          (layer): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (1): Conv2dBlock(\n",
              "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (layer): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (2): Conv2dBlock(\n",
              "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (layer): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (3): Conv2dBlock(\n",
              "          (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "          (layer): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): Identity()\n",
              "        )\n",
              "      )\n",
              "      (postprocess): Identity()\n",
              "    )\n",
              "    (1): AdaptiveAvgPool2d(output_size=1)\n",
              "    (2): MultiLayerPerceptron(\n",
              "      (blocks): LayerList(\n",
              "        (0): LinearBlock(\n",
              "          (layer): Linear(in_features=128, out_features=10, bias=True)\n",
              "          (activation): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (optimizer): Adam[Adam](lr=0.001)\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Optional\n",
        "\n",
        "class ImageClassifier(dl.Application):\n",
        "\n",
        "    model: nn.Module\n",
        "    optimizer: dl.Optimizer\n",
        "\n",
        "    def __init__(self, model: nn.Module, optimizer: Optional[dl.Optimizer] = None):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer or dl.Adam(lr=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return self.create_optimizer_with_params(self.optimizer, self.parameters())\n",
        "    \n",
        "classifier = ImageClassifier(net).create()\n",
        "classifier"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
