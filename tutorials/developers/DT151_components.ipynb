{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Should Be Implemented as a Component?\n",
    "\n",
    "The first step is to ensure that what you want to implement is actually a component.\n",
    "Most components are composed of several blocks, with a mostly sequential forward pass.\n",
    "They are intended to be used as parts of a model, and are not models themselves.\n",
    "\n",
    "A component should have the flexibility in the input arguments to the constructor to\n",
    "define the architecture of the component, including the number of layers, the number of units in each layer, and some important hyperparameters.\n",
    "\n",
    "Examples of components are `ConvolutionalNeuralNetwork` and `MultiLayerPerceptron`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Component\n",
    "\n",
    "Here you'll see the steps you should follow to implement a component in deeplay. As an example, you'll implement the `ConvolutionalNeuralNetwork`component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a New File\n",
    "\n",
    "The first step is to create a new file in the `deeplay/components` directory. It\n",
    "can be in a deeper subdirectory if it makes sense.\n",
    "\n",
    "**The base class.**\n",
    "Components generally don't have a specific base class. Sometimes it makes sense to subclass an existing component, but it is not necessary. If not, use `DeeplayModule` as the base class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example implements the `ConvolutionalNeuralNetwork` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay.blocks import Conv2dBlock\n",
    "from deeplay.list import Sequential\n",
    "from deeplay.module import DeeplayModule\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvolutionalNeuralNetwork(DeeplayModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels,\n",
    "        hidden_channels,\n",
    "        out_channels,\n",
    "        out_activation=nn.ReLU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        blocks = Sequential[Conv2dBlock]()\n",
    "        for in_ch, out_ch in zip([in_channels] + hidden_channels, \n",
    "                                 hidden_channels + [out_channels]):\n",
    "            block = Conv2dBlock(in_ch, out_ch, kernel_size=3, padding=0, \n",
    "                                activation=nn.ReLU)\n",
    "            blocks.append(block)\n",
    "        \n",
    "        # Set the activation function of the last block.\n",
    "        blocks[-1].activated(out_activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add Annotations\n",
    "\n",
    "It is important to add annotations to the class and methods to ensure that the\n",
    "user knows what to expect. This is also useful for the IDE to provide \n",
    "autocomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Type\n",
    "from deeplay.list import Sequential\n",
    "import torch\n",
    "\n",
    "class ConvolutionalNeuralNetwork(DeeplayModule):\n",
    "\n",
    "    # Arguments.\n",
    "    in_channels: int\n",
    "    hidden_channels: List[int]\n",
    "    out_channels: int\n",
    "    out_activation: Type[nn.Module]\n",
    "\n",
    "    # Attributes.\n",
    "    blocks: Sequential[Conv2dBlock]\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int,\n",
    "        hidden_channels: List[int],\n",
    "        out_channels: int,\n",
    "        out_activation: Type[nn.Module] = nn.ReLU,\n",
    "    ) -> None:  \n",
    "        super().__init__()\n",
    "\n",
    "        blocks = Sequential[Conv2dBlock]()\n",
    "        for in_ch, out_ch in zip([in_channels] + hidden_channels, \n",
    "                                 hidden_channels + [out_channels]):\n",
    "            block = Conv2dBlock(in_ch, out_ch, kernel_size=3, padding=0, \n",
    "                                activation=nn.ReLU)\n",
    "            blocks.append(block)\n",
    "        \n",
    "        # Set the activation function of the last block.\n",
    "        blocks[-1].activated(out_activation)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor,\n",
    "    ) -> torch.Tensor: \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Document the Component\n",
    "\n",
    "The next step is to document the component. This should include a description of \n",
    "the component, the input and output shapes, and the arguments that can be passed to\n",
    "the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(DeeplayModule):\n",
    "    \"\"\"A fully convolutional neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        The number of input channels.\n",
    "    hidden_channels : List[int]\n",
    "        The number of hidden channels.\n",
    "    out_channels : int\n",
    "        The number of output channels.\n",
    "    out_activation : Type[nn.Module]\n",
    "        The type of activation function of the output layer.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    blocks : Sequential[Conv2dBlock]\n",
    "        The list of convolutional blocks.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    x : torch.Tensor\n",
    "        The input tensor of shape (N, C, H, W).\n",
    "        Where N is the batch size, C is the number of channels, H is the \n",
    "        height, and W is the width.\n",
    "        Additial dimensions before C are allowed.\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    y : torch.Tensor\n",
    "        The output tensor of shape (N, out_channels, H', W').\n",
    "        Where N is the batch size, out_channels is the number of output \n",
    "        channels, H is the height, and W is the width.\n",
    "        Additial dimensions before out_channels will be preserved.\n",
    "\n",
    "    Evaluation\n",
    "    ----------\n",
    "    ```python\n",
    "    for block in blocks:\n",
    "        x = block(x)\n",
    "    ```\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cnn = ConvolutionalNeuralNetwork(3, [6, 6], 12).build()\n",
    "    >>> x = torch.randn(3, 3, 32, 32)\n",
    "    >>> y = cnn(x)\n",
    "    >>> y.shape\n",
    "    torch.Size([3, 12, 26, 26])\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Arguments.\n",
    "    in_channels: int\n",
    "    hidden_channels: List[int]\n",
    "    out_channels: int\n",
    "    out_activation: Type[nn.Module]\n",
    "\n",
    "    # Attributes.\n",
    "    blocks: Sequential[Conv2dBlock]\n",
    "\n",
    "    def __init__( \n",
    "        self, \n",
    "        in_channels: int,\n",
    "        hidden_channels: List[int],\n",
    "        out_channels: int,\n",
    "        out_activation: Type[nn.Module] = nn.ReLU,\n",
    "    ) -> None:  \n",
    "        super().__init__()\n",
    "\n",
    "        blocks = Sequential[Conv2dBlock]()\n",
    "        for in_ch, out_ch in zip([in_channels] + hidden_channels, \n",
    "                                 hidden_channels + [out_channels]):\n",
    "            block = Conv2dBlock(in_ch, out_ch, kernel_size=3, padding=0, \n",
    "                                activation=nn.ReLU)\n",
    "            blocks.append(block)\n",
    "        \n",
    "        # Set the activation function of the last block.\n",
    "        blocks[-1].activated(out_activation)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor,  \n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the convolutional neural network.\n",
    "\n",
    "        Evaluates the convolutional blocks sequentially.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            The input tensor of shape (N, C, H, W).\n",
    "            Where N is the batch size, C is the number of channels, H is the \n",
    "            height, and W is the width.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The output tensor of shape (N, out_channels, H', W').\n",
    "            Where N is the batch size, out_channels is the number of output \n",
    "            channels, H is the height, and W is the width.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define Properties\n",
    "\n",
    "There are some properties that should be defined in a component:\n",
    "- `input`: The input block of the component.\n",
    "- `output`: The output block of the component.\n",
    "- `hidden`: The hidden blocks of the component (all except output).\n",
    "These should generally be defined before the constructor, but after the annotations.\n",
    "\n",
    "In the current example, this corresponds to the code:\n",
    "```python\n",
    "    @property\n",
    "    def input(self) -> Conv2dBlock:\n",
    "        return self.blocks[0]\n",
    "    \n",
    "    @property\n",
    "    def output(self) -> Conv2dBlock:\n",
    "        return self.blocks[-1]\n",
    "    \n",
    "    @property\n",
    "    def hidden(self) -> ReferringLayerList[Conv2dBlock]:\n",
    "        return self.blocks[:-1]\n",
    "```\n",
    "\n",
    "**NOTE:** If you subclass another component, it is likely that these will already be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay.list import ReferringLayerList\n",
    "\n",
    "class ConvolutionalNeuralNetwork(DeeplayModule):\n",
    "    \"\"\"A fully convolutional neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        The number of input channels.\n",
    "    hidden_channels : List[int]\n",
    "        The number of hidden channels.\n",
    "    out_channels : int\n",
    "        The number of output channels.\n",
    "    out_activation : Type[nn.Module]\n",
    "        The type of activation function of the output layer.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    blocks : Sequential[Conv2dBlock]\n",
    "        The list of convolutional blocks.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    x : torch.Tensor\n",
    "        The input tensor of shape (N, C, H, W).\n",
    "        Where N is the batch size, C is the number of channels, H is the \n",
    "        height, and W is the width.\n",
    "        Additial dimensions before C are allowed.\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    y : torch.Tensor\n",
    "        The output tensor of shape (N, out_channels, H', W').\n",
    "        Where N is the batch size, out_channels is the number of output \n",
    "        channels, H is the height, and W is the width.\n",
    "        Additial dimensions before out_channels will be preserved.\n",
    "\n",
    "    Evaluation\n",
    "    ----------\n",
    "    ```python\n",
    "    for block in blocks:\n",
    "        x = block(x)\n",
    "    ```\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cnn = ConvolutionalNeuralNetwork(3, [6, 6], 12).build()\n",
    "    >>> x = torch.randn(3, 3, 32, 32)\n",
    "    >>> y = cnn(x)\n",
    "    >>> y.shape\n",
    "    torch.Size([3, 12, 26, 26])\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Arguments.\n",
    "    in_channels: int\n",
    "    hidden_channels: List[int]\n",
    "    out_channels: int\n",
    "    out_activation: Type[nn.Module]\n",
    "\n",
    "    # Attributes.\n",
    "    blocks: Sequential[Conv2dBlock]\n",
    "    \n",
    "    @property\n",
    "    def input(self) -> Conv2dBlock:\n",
    "        return self.blocks[0]\n",
    "    \n",
    "    @property\n",
    "    def output(self) -> Conv2dBlock:\n",
    "        return self.blocks[-1]\n",
    "    \n",
    "    @property\n",
    "    def hidden(self) -> ReferringLayerList[Conv2dBlock]:\n",
    "        return self.blocks[:-1]\n",
    "\n",
    "    def __init__( \n",
    "        self, \n",
    "        in_channels: int,\n",
    "        hidden_channels: List[int],\n",
    "        out_channels: int,\n",
    "        out_activation: Type[nn.Module] = nn.ReLU,\n",
    "    ) -> None: \n",
    "        super().__init__()\n",
    "\n",
    "        blocks = Sequential[Conv2dBlock]()\n",
    "        for in_ch, out_ch in zip([in_channels] + hidden_channels, \n",
    "                                 hidden_channels + [out_channels]):\n",
    "            block = Conv2dBlock(in_ch, out_ch, kernel_size=3, padding=0, \n",
    "                                activation=nn.ReLU)\n",
    "            blocks.append(block)\n",
    "        \n",
    "        # Set the activation function of the last block.\n",
    "        blocks[-1].activated(out_activation)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor,  \n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the convolutional neural network.\n",
    "\n",
    "        Evaluates the convolutional blocks sequentially.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            The input tensor of shape (N, C, H, W).\n",
    "            Where N is the batch size, C is the number of channels, H is the \n",
    "            height, and W is the width.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The output tensor of shape (N, out_channels, H', W').\n",
    "            Where N is the batch size, out_channels is the number of output \n",
    "            channels, H is the height, and W is the width.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implement Auxiliary Methods\n",
    "\n",
    "It might make sense to add additional auxiliary methods to the component. These should generally be convenience methods for complex configurations. For example, a \n",
    "`ConvolutionalNeuralNetwork` could have a `pooled` method that adds pooling layers\n",
    "to each block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay.external.layer import Layer\n",
    "from typing_extensions import Self\n",
    "\n",
    "class ConvolutionalNeuralNetwork(DeeplayModule):\n",
    "    \"\"\"A fully convolutional neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        The number of input channels.\n",
    "    hidden_channels : List[int]\n",
    "        The number of hidden channels.\n",
    "    out_channels : int\n",
    "        The number of output channels.\n",
    "    out_activation : Type[nn.Module]\n",
    "        The type of activation function of the output layer.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    blocks : Sequential[Conv2dBlock]\n",
    "        The list of convolutional blocks.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    x : torch.Tensor\n",
    "        The input tensor of shape (N, C, H, W).\n",
    "        Where N is the batch size, C is the number of channels, H is the \n",
    "        height, and W is the width.\n",
    "        Additial dimensions before C are allowed.\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    y : torch.Tensor\n",
    "        The output tensor of shape (N, out_channels, H', W').\n",
    "        Where N is the batch size, out_channels is the number of output \n",
    "        channels, H is the height, and W is the width.\n",
    "        Additial dimensions before out_channels will be preserved.\n",
    "\n",
    "    Evaluation\n",
    "    ----------\n",
    "    ```python\n",
    "    for block in blocks:\n",
    "        x = block(x)\n",
    "    ```\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cnn = ConvolutionalNeuralNetwork(3, [6, 6], 12).build()\n",
    "    >>> x = torch.randn(3, 3, 32, 32)\n",
    "    >>> y = cnn(x)\n",
    "    >>> y.shape\n",
    "    torch.Size([3, 12, 26, 26])\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Arguments.\n",
    "    in_channels: int\n",
    "    hidden_channels: List[int]\n",
    "    out_channels: int\n",
    "    out_activation: Type[nn.Module]\n",
    "\n",
    "    # Attributes.\n",
    "    blocks: Sequential[Conv2dBlock]\n",
    "    \n",
    "    @property\n",
    "    def input(self) -> Conv2dBlock:\n",
    "        return self.blocks[0]\n",
    "    \n",
    "    @property\n",
    "    def output(self) -> Conv2dBlock:\n",
    "        return self.blocks[-1]\n",
    "    \n",
    "    @property\n",
    "    def hidden(self) -> ReferringLayerList[Conv2dBlock]:\n",
    "        return self.blocks[:-1]\n",
    "\n",
    "    def __init__( \n",
    "        self, \n",
    "        in_channels: int,\n",
    "        hidden_channels: List[int],\n",
    "        out_channels: int,\n",
    "        out_activation: Type[nn.Module] = nn.ReLU,\n",
    "    ) -> None:  \n",
    "        super().__init__()\n",
    "\n",
    "        blocks = Sequential[Conv2dBlock]()\n",
    "        for in_ch, out_ch in zip([in_channels] + hidden_channels, \n",
    "                                 hidden_channels + [out_channels]):\n",
    "            block = Conv2dBlock(in_ch, out_ch, kernel_size=3, padding=0, \n",
    "                                activation=nn.ReLU)\n",
    "            blocks.append(block)\n",
    "        \n",
    "        # Set the activation function of the last block.\n",
    "        blocks[-1].activated(out_activation)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor,  \n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the convolutional neural network.\n",
    "\n",
    "        Evaluates the convolutional blocks sequentially.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            The input tensor of shape (N, C, H, W).\n",
    "            Where N is the batch size, C is the number of channels, H is the \n",
    "            height, and W is the width.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The output tensor of shape (N, out_channels, H', W').\n",
    "            Where N is the batch size, out_channels is the number of output \n",
    "            channels, H is the height, and W is the width.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "    def pooled(self, \n",
    "               pool: Layer = Layer(nn.MaxPool2d, 2),\n",
    "               apply_to_first: bool = False,\n",
    "               apply_to_last: bool = True) -> Self:\n",
    "        \"\"\"Add pooling layers after each block.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pool : Layer\n",
    "            The pooling layer.\n",
    "        apply_to_first : bool\n",
    "            Whether to apply pooling to the first block.\n",
    "        apply_to_last : bool\n",
    "            Whether to apply pooling to the last block.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if apply_to_first:\n",
    "            self.input.pooled(pool)\n",
    "        if apply_to_last:\n",
    "            self.output.pooled(pool)\n",
    "\n",
    "        for block in self.hidden[1:]:\n",
    "            block.pooled(pool)\n",
    "\n",
    "        return self"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env_dlcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
