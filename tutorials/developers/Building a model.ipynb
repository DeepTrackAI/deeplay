{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a model\n",
    "\n",
    "Here we will show the steps you should follow to implement a model in deeplay.\n",
    "\n",
    "## 1. Should I implement a model?\n",
    "\n",
    "The first step is to ensure that what you want to implement is actually a model.\n",
    "Most models are composed of a few named components (e.g. ConvolutionalNeuralNetwork),\n",
    "and generally intended as a complete transformation from input to output for a task.\n",
    "\n",
    "Most models are standard nerual networks with exact architectures (like ResNet50), but\n",
    "models can also be more general, like a RecurrentModel. \n",
    "\n",
    "Unlike components, models generally have a more rigid structure. It is not expected that\n",
    "the number if blocks or the sizes of the layers can be defined in the input arguments. \n",
    "However, if possible, the input and output shapes should be flexible.\n",
    "\n",
    "Examples of models are:\n",
    "- ViT\n",
    "- CycleGANGenerator\n",
    "- ResNet50\n",
    "- RecurrentModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing the model\n",
    "\n",
    "The first step is to create a new file in the `deeplay/models` directory. It\n",
    "can be in a deeper subdirectory if it makes sense.\n",
    "\n",
    "# 2.1 The base class\n",
    "\n",
    "models generally does not have a base class. Sometimes it makes sense to subclass an\n",
    "existing model, but it is not necessary. It is in some cases possible to subclass a\n",
    "component, if the model is simply that component with some additional layers or with\n",
    "an exact architecture.\n",
    "\n",
    "If neither are applicable, use `DeeplayModule` as the base class.\n",
    "\n",
    "# 2.2 Example, ResNet18\n",
    "\n",
    "Special for the implementation of models is the expectation to used styled components\n",
    "and blocks where possible. This is to ensure that the modules can be reused in other\n",
    "models.\n",
    "\n",
    "## 2.2.1 The ResNet18 block\n",
    "\n",
    "First we implement the resnet block. This is a styled block, and should be implemented\n",
    "in the same file as the model.\n",
    "\n",
    "Note, the style should have a small docstring, as though it was a method. The first\n",
    "argument should not be documented (just as `self` is not documented in methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dBlock(\n",
       "  (blocks): Sequential(\n",
       "    (0-1): 2 x Conv2dBlock(\n",
       "      (shortcut_start): Conv2dBlock(\n",
       "        (layer): Layer[Identity](in_channels=16, out_channels=16, kernel_size=1, stride=1, padding=0)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv2dBlock(\n",
       "          (layer): Layer[Conv2d](in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
       "          (normalization): Layer[BatchNorm2d](num_features=16)\n",
       "          (activation): Layer[ReLU]()\n",
       "        )\n",
       "        (1): Conv2dBlock(\n",
       "          (layer): Layer[Conv2d](in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
       "          (normalization): Layer[BatchNorm2d](num_features=16)\n",
       "        )\n",
       "      )\n",
       "      (shortcut_end): Add()\n",
       "      (activation): Layer[ReLU]()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deeplay.blocks import Conv2dBlock\n",
    "\n",
    "@Conv2dBlock.register_style\n",
    "def resnet(block: Conv2dBlock, stride: int = 1):\n",
    "    \"\"\"ResNet style block composed of two residual blocks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stride : int\n",
    "        Stride of the first block, by default 1\n",
    "    \"\"\"\n",
    "    # 1. create two blocks\n",
    "    block.multi(2)\n",
    "\n",
    "    # 2. make the two blocks\n",
    "    block.blocks[0].style(\"residual\", order=\"lnaln|a\")\n",
    "    block.blocks[1].style(\"residual\", order=\"lnaln|a\")\n",
    "\n",
    "    # 3. if stride > 1, stride the first block and add normalization to the shortcut\n",
    "    if stride > 1:\n",
    "        block.blocks[0].strided(stride)\n",
    "        block.blocks[0].shortcut_start.normalized()\n",
    "\n",
    "    # 4. remove the pooling layer if it exists.\n",
    "    block[...].isinstance(Conv2dBlock).all.remove(\"pool\", allow_missing=True)\n",
    "\n",
    "block = Conv2dBlock(16, 16).style(\"resnet\")\n",
    "block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 The ResNet18 input block\n",
    "\n",
    "The input block is slightly different from the normal block. We also implement this\n",
    "as a styled block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dBlock(\n",
       "  (layer): Layer[Conv2d](in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
       "  (normalization): Layer[BatchNorm2d](num_features=64)\n",
       "  (activation): Layer[ReLU](inplace=True)\n",
       "  (pool): Layer[MaxPool2d](kernel_size=3, stride=2, padding=1, ceil_mode=False, dilation=1)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deeplay.external.layer import Layer\n",
    "import torch.nn as nn\n",
    "\n",
    "@Conv2dBlock.register_style\n",
    "def resnet18_input(block: Conv2dBlock):\n",
    "    \"\"\"ResNet18 input block.\n",
    "\n",
    "    The block used on the input of the ResNet18 architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    block.configure(kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    block.normalized(mode=\"insert\", after=\"layer\")\n",
    "    block.activated(Layer(nn.ReLU, inplace=True), mode=\"insert\", after=\"normalization\")\n",
    "    pool = Layer(nn.MaxPool2d, kernel_size=3, stride=2, padding=1, ceil_mode=False, \n",
    "                 dilation=1)\n",
    "    block.pooled(pool, mode=\"append\")\n",
    "\n",
    "block = Conv2dBlock(3, 64).style(\"resnet18_input\")\n",
    "block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.3 The ResNet18 backbone\n",
    "\n",
    "The backbone is a styled component, and should be implemented in the same file as the\n",
    "model. As it is a convolutional encoder, we style a `ConvolutionalEncoder2d` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalEncoder2d(\n",
       "  (blocks): LayerList(\n",
       "    (0): Conv2dBlock(\n",
       "      (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=7, stride=2, padding=3)\n",
       "      (normalization): Layer[BatchNorm2d](num_features=16)\n",
       "      (activation): Layer[ReLU](inplace=True)\n",
       "      (pool): Layer[MaxPool2d](kernel_size=3, stride=2, padding=1, ceil_mode=False, dilation=1)\n",
       "    )\n",
       "    (1): Conv2dBlock(\n",
       "      (blocks): Sequential(\n",
       "        (0): Conv2dBlock(\n",
       "          (shortcut_start): Conv2dBlock(\n",
       "            (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=1, stride=1, padding=0)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): Conv2dBlock(\n",
       "              (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
       "              (normalization): Layer[BatchNorm2d](num_features=32)\n",
       "              (activation): Layer[ReLU]()\n",
       "            )\n",
       "            (1): Conv2dBlock(\n",
       "              (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
       "              (normalization): Layer[BatchNorm2d](num_features=32)\n",
       "            )\n",
       "          )\n",
       "          (shortcut_end): Add()\n",
       "          (activation): Layer[ReLU]()\n",
       "        )\n",
       "        (1): Conv2dBlock(\n",
       "          (shortcut_start): Conv2dBlock(\n",
       "            (layer): Layer[Identity](in_channels=32, out_channels=32, kernel_size=1, stride=1, padding=0)\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): Conv2dBlock(\n",
       "              (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
       "              (normalization): Layer[BatchNorm2d](num_features=32)\n",
       "              (activation): Layer[ReLU]()\n",
       "            )\n",
       "            (1): Conv2dBlock(\n",
       "              (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
       "              (normalization): Layer[BatchNorm2d](num_features=32)\n",
       "            )\n",
       "          )\n",
       "          (shortcut_end): Add()\n",
       "          (activation): Layer[ReLU]()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (postprocess): Layer[AdaptiveAvgPool2d](output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deeplay.components import ConvolutionalEncoder2d\n",
    "from deeplay.initializers import Kaiming, Constant\n",
    "\n",
    "@ConvolutionalEncoder2d.register_style\n",
    "def resnet18(encoder: ConvolutionalEncoder2d, \n",
    "             pool_output: bool = True,\n",
    "             set_hidden_channels: bool = False):\n",
    "    \"\"\"ResNet18 backbone.\n",
    "\n",
    "    Styles a ConvolutionalEncoder2d to have the ResNet18 architecture.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pool_output : bool\n",
    "        Whether to append a pooling layer at the end of the encoder, by default True\n",
    "    set_hidden_channels : bool\n",
    "        Whether to set the hidden channels to the default ResNet18 values, by default \n",
    "        False\n",
    "    \"\"\"\n",
    "\n",
    "    if set_hidden_channels:\n",
    "        encoder.configure(hidden_channels=[64, 64, 128, 256])\n",
    "\n",
    "    # 1. style the first block\n",
    "    encoder.blocks[0].style(\"resnet18_input\")\n",
    "    # 2. the second block does not have a stride\n",
    "    encoder.blocks[1].style(\"resnet\", stride=1)\n",
    "\n",
    "    # 3. the rest of the blocks have a stride of 2\n",
    "    encoder[\"blocks\", 2:].hasattr(\"style\").all.style(\"resnet\", stride=2)\n",
    "\n",
    "    # 4. initialize the weights\n",
    "    encoder.initialize(Kaiming(targets=(nn.Conv2d,)))\n",
    "    encoder.initialize(Constant(targets=(nn.BatchNorm2d,)))\n",
    "\n",
    "    # 5. set postprocess to pool the output if needed\n",
    "    if pool_output:\n",
    "        encoder.postprocess.configure(nn.AdaptiveAvgPool2d, output_size=(1, 1))\n",
    "        \n",
    "encoder = ConvolutionalEncoder2d(3, [16], 32).style(\"resnet18\", pool_output=True)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 The ResNet18 model\n",
    "\n",
    "Finally, we implement the model. We subclass `DeeplayModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay.module import DeeplayModule\n",
    "from deeplay.components import MultiLayerPerceptron\n",
    "\n",
    "class ResNet18(DeeplayModule):\n",
    "\n",
    "    def __init__(self, in_channels: int = 3, latent_channels: int = 512, num_classes: int = 1000):\n",
    "        self.backbone = ConvolutionalEncoder2d(\n",
    "            in_channels, \n",
    "            [64, 64, 128, 256, 512], \n",
    "            latent_channels\n",
    "        )\n",
    "        self.backbone.style(\"resnet18\", pool_output=True)\n",
    "\n",
    "        self.head = MultiLayerPerceptron(latent_channels, [], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Annotations\n",
    "\n",
    "It is important to add annotations to the class and methods to ensure that the\n",
    "user knows what to expect. This is also useful for the IDE to provide \n",
    "autocomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplay.module import DeeplayModule\n",
    "from deeplay.components import MultiLayerPerceptron\n",
    "\n",
    "class ResNet18(DeeplayModule):\n",
    "\n",
    "    backbone: ConvolutionalEncoder2d\n",
    "    head: MultiLayerPerceptron\n",
    "\n",
    "    def __init__(self, in_channels: int = 3, latent_channels: int = 512, num_classes: int = 1000):\n",
    "        self.backbone = ConvolutionalEncoder2d(\n",
    "            in_channels, \n",
    "            [64, 64, 128, 256, 512], \n",
    "            latent_channels\n",
    "        )\n",
    "        self.backbone.style(\"resnet18\", pool_output=True)\n",
    "\n",
    "        self.head = MultiLayerPerceptron(latent_channels, [], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Documenting the model\n",
    "\n",
    "The next step is to document the model. This should include a description of \n",
    "the model, the input and output shapes, and the arguments that can be passed to\n",
    "the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(DeeplayModule):\n",
    "    \"\"\"A ResNet18 model.\n",
    "\n",
    "    A ResNet18 model composed of a ConvolutionalEncoder2d backbone and a MultiLayerPerceptron head.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        The number of input channels, by default 3\n",
    "    latent_channels : int\n",
    "        The number of latent channels (at the end of the backbone), by default 512\n",
    "    num_classes : int\n",
    "        The number of classes, by default 1000\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    backbone : ConvolutionalEncoder2d\n",
    "        The backbone of the model\n",
    "    head : MultiLayerPerceptron\n",
    "        The head of the model. By default a simple linear layer.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    x : torch.Tensor\n",
    "        The input tensor of shape (N, in_channels, H, W).\n",
    "        Where N is the batch size, in_channels is the number of input channels,\n",
    "        H is the height, and W is the width.\n",
    "        H and W should be at least 33, but ideally 224.\n",
    "\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    y : torch.Tensor\n",
    "        The output tensor of shape (N, num_classes).\n",
    "        Where N is the batch size and num_classes is the number of classes.\n",
    "\n",
    "    Evaluation\n",
    "    ----------\n",
    "    ```python\n",
    "    x = backbone(x)\n",
    "    x = head(x)\n",
    "    ```\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> model = ResNet18(3, 512, 1000).build()\n",
    "    >>> x = torch.randn(4, 3, 224, 224)\n",
    "    >>> y = model(x)\n",
    "    >>> y.shape\n",
    "    torch.Size([4, 1000])\n",
    "\n",
    "    \"\"\"\n",
    "    # [rest of the code]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
